{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294de200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (0.22.0)\n",
      "Requirement already satisfied: torchaudio in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: numpy in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers) (0.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from nltk) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✅ Dependencies loaded.\n",
      "\n",
      "=== sentiment-topic-test.tsv (Test set) ===\n",
      "Rows: 18, Columns: ['sentence_id', 'sentence', 'sentiment', 'topic']\n",
      "\n",
      " sentence_id                                                                         sentence sentiment  topic\n",
      "           0      The stadium was alive with the roar of the crowd after that incredible win.  positive sports\n",
      "           1 That last-minute goal had me jumping out of my seat—what an unbelievable finish!  positive sports\n",
      "           2                I couldn’t put the book down; it swept me into a whole new world.  positive   book \n",
      "\n",
      "=== NER-test.tsv (Token-level Test set) ===\n",
      "Rows: 216, Columns: ['sentence_id', 'token_id', 'token', 'BIO_NER_tag']\n",
      "\n",
      " sentence_id  token_id    token BIO_NER_tag\n",
      "           0         0       If           O\n",
      "           0         1   you're           O\n",
      "           0         2 visiting           O \n",
      "\n",
      "=== Reconstructed NER Sentences (first 5) ===\n",
      " sentence_id                                                                                                        sentence\n",
      "           0                        If you're visiting Paris , make sure to see the Louvre , as they exhibit the Mona Lisa !\n",
      "           1                               Amazon , Google and Meta control a huge share of the technology market globally .\n",
      "           2                                           Did you hear Pharoah Sanders recorded an album with Floating Points ?\n",
      "           3                                                              Madvillainy is still my favourite MF DOOM record .\n",
      "           4 My friend Kevin just finished watching Succession , and won't stop talking about Kieran Culkin 's performance . \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/rayanelmourabit/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n",
      "/Users/rayanelmourabit/anaconda3/envs/py312/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NER Predictions (first 5) ===\n",
      " sentence_id                                                     predicted_entities\n",
      "           0            [(Paris, LOC), (Lou, ORG), (##vre, LOC), (Mona Lisa, MISC)]\n",
      "           1                            [(Amazon, ORG), (Google, ORG), (Meta, ORG)]\n",
      "           2 [(Ph, PER), (##aro, PER), (##ah Sanders, PER), (Floating Points, ORG)]\n",
      "           3                                                                     []\n",
      "           4    [(Kevin, PER), (Succession, MISC), (Ki, PER), (##eran Culkin, PER)] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sentiment: Gold vs. VADER vs. Hybrid Zero-Shot+KWD (first 5) ===\n",
      "                                                                             sentence sentiment vader_sentiment zs_sentiment\n",
      "          The stadium was alive with the roar of the crowd after that incredible win.  positive        positive     positive\n",
      "     That last-minute goal had me jumping out of my seat—what an unbelievable finish!  positive        positive     positive\n",
      "                    I couldn’t put the book down; it swept me into a whole new world.  positive         neutral     positive\n",
      "        The story had its moments, though some parts felt like they dragged on a bit.   neutral        positive     negative\n",
      "I enjoyed the way the timelines shifted, even if it got a little confusing sometimes.   neutral        positive     positive \n",
      "\n",
      "=== VADER Sentiment Classification Report (Test) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.17      0.29         6\n",
      "     neutral       0.20      0.17      0.18         6\n",
      "    positive       0.25      0.50      0.33         6\n",
      "\n",
      "    accuracy                           0.28        18\n",
      "   macro avg       0.48      0.28      0.27        18\n",
      "weighted avg       0.48      0.28      0.27        18\n",
      " \n",
      "\n",
      "=== Hybrid Zero-Shot+KWD Sentiment Classification Report (Test) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      1.00      0.92         6\n",
      "     neutral       1.00      0.50      0.67         6\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.87      0.83      0.82        18\n",
      "weighted avg       0.87      0.83      0.82        18\n",
      " \n",
      "\n",
      "=== Examples where VADER vs. Hybrid differ (first 5) ===\n",
      "                                                                                     sentence sentiment vader_sentiment zs_sentiment\n",
      "                            I couldn’t put the book down; it swept me into a whole new world.  positive         neutral     positive\n",
      "                The story had its moments, though some parts felt like they dragged on a bit.   neutral        positive     negative\n",
      "                Every time I watch this movie, I notice something new—it really grows on you.  positive         neutral     positive\n",
      "The movie was a wild ride from start to finish; I was on the edge of my seat the entire time.  positive         neutral     positive\n",
      "           Honestly, the team just fell apart in the second half, and it showed on the field.  negative        positive     negative \n",
      "\n",
      "=== Topic (Gold vs. Hybrid) on Test Set (first 5) ===\n",
      "                                                                             sentence  topic pred_topic\n",
      "          The stadium was alive with the roar of the crowd after that incredible win. sports     sports\n",
      "     That last-minute goal had me jumping out of my seat—what an unbelievable finish! sports     sports\n",
      "                    I couldn’t put the book down; it swept me into a whole new world.   book       book\n",
      "        The story had its moments, though some parts felt like they dragged on a bit.   book      movie\n",
      "I enjoyed the way the timelines shifted, even if it got a little confusing sometimes.   book      movie \n",
      "\n",
      "=== Topic Classification Report (Hybrid) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sports       1.00      1.00      1.00         6\n",
      "        book       1.00      0.50      0.67         6\n",
      "       movie       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.89      0.83      0.82        18\n",
      "weighted avg       0.89      0.83      0.82        18\n",
      " \n",
      "\n",
      "All predictions saved to CSV. ✅\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install transformers\n",
    "%pip install nltk\n",
    "%pip install scikit-learn\n",
    "%pip install pandas\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoModelForSequenceClassification,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "print(\"✅ Dependencies loaded.\\n\")\n",
    "\n",
    "\n",
    "sent_topic_df = pd.read_csv('sentiment-topic-test.tsv', sep='\\t', header=0)\n",
    "print(\"=== sentiment-topic-test.tsv (Test set) ===\")\n",
    "print(f\"Rows: {len(sent_topic_df)}, Columns: {sent_topic_df.columns.tolist()}\\n\")\n",
    "print(sent_topic_df.head(3).to_string(index=False), \"\\n\")\n",
    "\n",
    "token_df = pd.read_csv('NER-test.tsv', sep='\\t', header=0)\n",
    "print(\"=== NER-test.tsv (Token-level Test set) ===\")\n",
    "print(f\"Rows: {len(token_df)}, Columns: {token_df.columns.tolist()}\\n\")\n",
    "print(token_df.head(3).to_string(index=False), \"\\n\")\n",
    "\n",
    "sentence_records = []\n",
    "for sid, group in token_df.groupby('sentence_id'):\n",
    "    group = group.sort_values('token_id')\n",
    "    tokens = group['token'].tolist()\n",
    "    full_sentence = \" \".join(tokens)\n",
    "    sentence_records.append({'sentence_id': sid, 'sentence': full_sentence})\n",
    "\n",
    "ner_sent_df = pd.DataFrame(sentence_records)\n",
    "print(\"=== Reconstructed NER Sentences (first 5) ===\")\n",
    "print(ner_sent_df.head(5).to_string(index=False), \"\\n\")\n",
    "\n",
    "\n",
    "model_checkpoint = \"dslim/bert-base-NER\"\n",
    "tokenizer_ner = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model_ner = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "\n",
    "ner_pipeline = pipeline(\n",
    "    \"ner\",\n",
    "    model=model_ner,\n",
    "    tokenizer=tokenizer_ner,\n",
    "    grouped_entities=True\n",
    ")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'\\[?\\(?\\d{2}:\\d{2}:\\d{2}\\)?\\]?', '', text)\n",
    "    text = re.sub(r'^[A-Z ]{2,20}:', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "ner_sent_df['text_clean'] = ner_sent_df['sentence'].apply(preprocess_text)\n",
    "\n",
    "def extract_entities(text):\n",
    "    try:\n",
    "        results = ner_pipeline(text)\n",
    "        return [(ent['word'], ent['entity_group']) for ent in results]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "ner_sent_df['predicted_entities'] = ner_sent_df['text_clean'].apply(extract_entities)\n",
    "print(\"=== NER Predictions (first 5) ===\")\n",
    "print(ner_sent_df[['sentence_id', 'predicted_entities']].head(5).to_string(index=False), \"\\n\")\n",
    "\n",
    "\n",
    "# System A: VADER baseline\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def vader_baseline(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    c = scores['compound']\n",
    "    if c >= 0.05:\n",
    "        return 'positive'\n",
    "    elif c <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "sent_topic_df['vader_sentiment'] = sent_topic_df['sentence'].apply(vader_baseline)\n",
    "\n",
    "\n",
    "# System B: Hybrid zero‐shot (“negative”/“neutral”/“positive”) + keyword fallback\n",
    "\n",
    "# Load MNLI‐based zero‐shot classifier\n",
    "zs_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "zs_model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "zs_classifier = pipeline(\"zero-shot-classification\", model=zs_model, tokenizer=zs_tokenizer)\n",
    "\n",
    "# Define small domain‐specific sentiment keywords\n",
    "positive_keywords = {\n",
    "    \"win\", \"incredible\", \"unbelievable\", \"favourite\", \"love\", \"enjoyed\", \"best\", \"liked\", \"amazing\", \"excited\"\n",
    "}\n",
    "negative_keywords = {\n",
    "    \"dragged\", \"confusing\", \"fell\", \"apart\", \"disappointing\", \"disappointed\", \"hate\", \"bored\", \"worse\", \"boring\"\n",
    "}\n",
    "\n",
    "def hybrid_sentiment(text, zero_shot_threshold=0.7):\n",
    "    # 1) Zero-shot entailment step\n",
    "    out = zs_classifier(text, candidate_labels=[\"negative\",\"neutral\",\"positive\"])\n",
    "    top_label = out[\"labels\"][0]\n",
    "    top_score = out[\"scores\"][0]\n",
    "    if top_score >= zero_shot_threshold:\n",
    "        return top_label\n",
    "\n",
    "    # 2) Keyword fallback if MNLI is uncertain\n",
    "    tokens = {w.strip('.,!?;:\"\\'').lower() for w in text.split()}\n",
    "    if tokens & positive_keywords:\n",
    "        return \"positive\"\n",
    "    if tokens & negative_keywords:\n",
    "        return \"negative\"\n",
    "    return \"neutral\"\n",
    "\n",
    "sent_topic_df['zs_sentiment'] = sent_topic_df['sentence'].apply(hybrid_sentiment)\n",
    "\n",
    "print(\"=== Sentiment: Gold vs. VADER vs. Hybrid Zero-Shot+KWD (first 5) ===\")\n",
    "print(sent_topic_df[['sentence','sentiment','vader_sentiment','zs_sentiment']]\n",
    "      .head(5).to_string(index=False), \"\\n\")\n",
    "\n",
    "print(\"=== VADER Sentiment Classification Report (Test) ===\")\n",
    "print(classification_report(\n",
    "    sent_topic_df['sentiment'],\n",
    "    sent_topic_df['vader_sentiment'],\n",
    "    labels=['negative','neutral','positive'],\n",
    "    target_names=['negative','neutral','positive']\n",
    "), \"\\n\")\n",
    "\n",
    "print(\"=== Hybrid Zero-Shot+KWD Sentiment Classification Report (Test) ===\")\n",
    "print(classification_report(\n",
    "    sent_topic_df['sentiment'],\n",
    "    sent_topic_df['zs_sentiment'],\n",
    "    labels=['negative','neutral','positive'],\n",
    "    target_names=['negative','neutral','positive']\n",
    "), \"\\n\")\n",
    "\n",
    "# Show a few error‐analysis examples\n",
    "mismatch_df = sent_topic_df[sent_topic_df['vader_sentiment'] != sent_topic_df['zs_sentiment']]\n",
    "print(\"=== Examples where VADER vs. Hybrid differ (first 5) ===\")\n",
    "print(mismatch_df[['sentence','sentiment','vader_sentiment','zs_sentiment']].head(5).to_string(index=False), \"\\n\")\n",
    "\n",
    "\n",
    "candidate_labels = [\"sports\", \"book\", \"movie\"]\n",
    "\n",
    "topic_keywords_fallback = {\n",
    "    \"sports\": {\"sport\",\"game\",\"goal\",\"team\",\"score\",\"coach\",\"match\",\"stadium\",\"league\",\"win\"},\n",
    "    \"book\":   {\"book\",\"story\",\"author\",\"chapter\",\"novel\",\"read\",\"fiction\",\"page\",\"literature\",\"publish\"},\n",
    "    \"movie\":  {\"movie\",\"film\",\"actor\",\"actress\",\"director\",\"scene\",\"watch\",\"cinema\",\"screen\",\"dvd\"}\n",
    "}\n",
    "\n",
    "def hybrid_topic_classifier(sentence: str, threshold: float = 0.5) -> str:\n",
    "    out = zs_classifier(sentence, candidate_labels)\n",
    "    top_label = out['labels'][0]\n",
    "    top_score = out['scores'][0]\n",
    "    if top_score >= threshold:\n",
    "        return top_label\n",
    "    tokens = {w.strip('.,!?;:\"\\'').lower() for w in sentence.split()}\n",
    "    scores = {lbl: len(tokens & kws) for lbl, kws in topic_keywords_fallback.items()}\n",
    "    best_lbl = max(scores, key=scores.get)\n",
    "    return best_lbl if scores[best_lbl] > 0 else top_label\n",
    "\n",
    "sent_topic_df['pred_topic'] = sent_topic_df['sentence'].apply(hybrid_topic_classifier)\n",
    "\n",
    "print(\"=== Topic (Gold vs. Hybrid) on Test Set (first 5) ===\")\n",
    "print(sent_topic_df[['sentence','topic','pred_topic']].head(5).to_string(index=False), \"\\n\")\n",
    "\n",
    "print(\"=== Topic Classification Report (Hybrid) ===\")\n",
    "print(classification_report(\n",
    "    sent_topic_df['topic'],\n",
    "    sent_topic_df['pred_topic'],\n",
    "    labels=['sports','book','movie'],\n",
    "    target_names=['sports','book','movie']\n",
    "), \"\\n\")\n",
    "\n",
    "\n",
    "sent_topic_df.to_csv(\"sentiment_topic_test_predictions.csv\", index=False)\n",
    "ner_sent_df.to_csv(\"ner_test_predictions.csv\", index=False)\n",
    "\n",
    "print(\"All predictions saved to CSV. ✅\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9464a78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.17      0.29         6\n",
      "     neutral       0.20      0.17      0.18         6\n",
      "    positive       0.25      0.50      0.33         6\n",
      "\n",
      "    accuracy                           0.28        18\n",
      "   macro avg       0.48      0.28      0.27        18\n",
      "weighted avg       0.48      0.28      0.27        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(sent_topic_df['sentiment'], sent_topic_df['predicted_sentiment']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
